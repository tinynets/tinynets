# tinynets

## Inspiration & Motivation

Neural Networks are everywhere now, that happened quickly though perhaps not too "out of the blue",
if you have been following along. It is so easy to feel discouraged that the field is moving so fast
and that you are getting left behind. It is especially easy if you see that there's a "boom" in the 
economy, and there's courses and influencers and certifications everywhere and you feel like you are
left behind.

This combined with a general feeling and disdain that everything is a "Large. Language. Model." has
made things kind of **boring** . There's no real excitement on an individual level of any real
progress. The next thing. Is it more data? more GPUs? More training clusters and RAG? Better CUDA
Kernels? What ?

These thoughts, I will expand on more in the future, has motivated me to make things "smaller". 
There's nothing complicated about adding and multiplying numbers, if you start doing that and 
working upwards and only maintain the logic you need and very little else in a neural network, 
there's so much control you can exert.

There's so much to learn from that control as you plat with it. It is like doing brain surgery on a 
worm. A worm, that massive organizations (the frontier labs) have figured out how grow into monsters
and tame by feeding the ravenous beast with data and bathing it in Human Attention, in the form of
RLHF. Attention is all you need, lots of human attention to make the non human thing less perplexed.

I want to do whatever the opposite of that is for a little bit, by playfully hacking away at small
neural networks, and interacting with them to learn and grow with the tinynets.

---

tinynets is a set of tools written to make it easier to build, deploy and study small neural 
networks. "Small" in this case shall be defined as a neural network that can be reasonably trained,
and run on mid-range consumer hardware, You can read more about hardware in the hardware section.

## Hardware

I currently have a Macbook M1 Max, so code from tinynets should run on a machine at least that 
"powerful". The nature of the projects should contain additional documentation if deemed neccesary.

For the most part if you are dabbling with neural networks then you have the hardware needed to 
play with this code within reason.


# Disclaimer

I am not responsible for any of the consequences of anyone running the code from tinynets anywhere,
at any time.

